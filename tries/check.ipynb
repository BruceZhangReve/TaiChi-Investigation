{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "cpu\n",
      "ToyMLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=17, out_features=8, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=8, out_features=8, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=8, out_features=16, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import torch\n",
    "sys.path.append('/Users/zhanglige/Desktop/JP-Lab/Code/Velocity_Flow_Matching/')\n",
    "import dnnlib\n",
    "from training.networks import ToyMLP\n",
    "#set up device first\n",
    "device_name = 'cpu' #can swap this to cuda:0, etc pending on resources\n",
    "device = torch.device(device_name)\n",
    "print(device)\n",
    "mlp = ToyMLP(dim=16, time_varying=True, n_hidden=1, w=8)\n",
    "mlp.train().to(device)\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "JVP vector shape:  torch.Size([3, 1, 16])\n",
      "Jacobian Transpose Shape:  torch.Size([3, 16, 16])\n",
      "torch.Size([3, 16])\n"
     ]
    }
   ],
   "source": [
    "#first, set up inputs for net \n",
    "#am choosing small batch size to make computation faster \n",
    "batch_size = 3\n",
    "flat_data_dim = 16\n",
    "imgs = torch.randn(batch_size, flat_data_dim).type(torch.float32).to(device)\n",
    "ts = torch.rand(batch_size, device=device) \n",
    "#ok now calc Jacobian of net_out w.r.t imgs input \n",
    "#set requires_grad to True for net inputs... \n",
    "ts.requires_grad=True\n",
    "imgs.requires_grad=True\n",
    "\n",
    "\n",
    "mlp_jac = torch.autograd.functional.jacobian(mlp, (imgs, ts))\n",
    "#print(mlp_jac[0].shape)\n",
    "torch_jac = torch.sum(mlp_jac[0], dim=2) #collapse over extra batch dim, see comment above # then it would be img:(B,D',D)\n",
    "nabla_imgs = torch_jac.transpose(2,1) #transpose, to get gradient\n",
    "print()\n",
    "print(\"JVP vector shape: \",mlp(imgs, ts).unsqueeze(1).shape)\n",
    "print(\"Jacobian Transpose Shape: \", nabla_imgs.shape)#[B,D,D']\n",
    "imgs_jvp = torch.einsum('bij, bjk -> bik', mlp(imgs, ts).unsqueeze(1), nabla_imgs).squeeze(1) # (B,D)\n",
    "print(imgs_jvp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Current PyTorch device: cpu\n",
      "ToyMLP Structure:\n",
      " ToyMLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=9, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=8, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "JVP vector shape:  torch.Size([2, 8])\n",
      "PyTorch final JVP shape:  torch.Size([2, 8])\n",
      "[Taichi] version 1.7.2, llvm 15.0.5, commit 0131dce9, osx, python 3.9.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 03/18/25 20:56:54.572 787052] [shell.py:_shell_pop_print@23] Graphical python shell detected, using wrapped sys.stdout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] Starting on arch=x64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/taichi/lang/util.py:370: UserWarning: \u001b[33m\u001b[1mTaichi matrices/vectors with 4x9 > 32 entries are not suggested. Matrices/vectors will be automatically unrolled at compile-time for performance. So the compilation time could be extremely long if the matrix size is too big. You may use a field to store a large matrix like this, e.g.:\n",
      "    x = ti.field(ti.f32, (4, 9)).\n",
      " See https://docs.taichi-lang.org/docs/field#matrix-size for more details.\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/30/nv81x05d7w93bczkq13z20100000gn/T/ipykernel_10585/3541953398.py\", line 146, in <module>\n",
      "    W1[None] = W1_np\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/taichi/lang/util.py\", line 351, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/taichi/lang/matrix.py\", line 1358, in __setitem__\n",
      "    self[key]._set_entries(value)\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/taichi/lang/util.py\", line 351, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/zhanglige/opt/anaconda3/envs/Flow/lib/python3.9/site-packages/taichi/lang/matrix.py\", line 1367, in __getitem__\n",
      "    return Matrix([[_host_access[i * self.m + j] for j in range(self.m)] for i in range(self.n)])\n",
      "\u001b[0m\n",
      "  warnings.warn(Fore.YELLOW + Style.BRIGHT + msg + Style.RESET_ALL, warning_type)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "#                  1) PyTorch 部分\n",
    "#######################################################\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import torch\n",
    "\n",
    "# 这里是你原本的路径设置\n",
    "sys.path.append('/Users/zhanglige/Desktop/JP-Lab/Code/Velocity_Flow_Matching/')\n",
    "import dnnlib\n",
    "from training.networks import ToyMLP\n",
    "\n",
    "device_name = 'cpu'  # 可以根据需要切换 'cuda:0' 等\n",
    "device = torch.device(device_name)\n",
    "print(\"Current PyTorch device:\", device)\n",
    "\n",
    "# 构造网络 (注意：dim=16, time_varying=True => 输入其实是 16 + 1 = 17 维)\n",
    "mlp = ToyMLP(dim=8, time_varying=True, n_hidden=1, w=4)\n",
    "mlp.train().to(device)\n",
    "print(\"ToyMLP Structure:\\n\", mlp)\n",
    "\n",
    "# 准备输入\n",
    "batch_size = 2\n",
    "flat_data_dim = 8\n",
    "imgs = torch.randn(batch_size, flat_data_dim, device=device, dtype=torch.float32)\n",
    "ts = torch.rand(batch_size, device=device, dtype=torch.float32)\n",
    "# 需要求梯度\n",
    "imgs.requires_grad=True\n",
    "ts.requires_grad=True\n",
    "\n",
    "# ---------------- 计算 Jacobian + 处理 + JVP ----------------\n",
    "mlp_jac = torch.autograd.functional.jacobian(mlp, (imgs, ts))\n",
    "# mlp_jac[0] => wrt imgs, shape通常是 [batch, out_dim, batch, in_dim]\n",
    "# 根据你的注释，你是要在 dim=2 处进行 sum\n",
    "torch_jac = torch.sum(mlp_jac[0], dim=2)  # => shape [B, out_dim, in_dim]\n",
    "nabla_imgs = torch_jac.transpose(2, 1)   # => shape [B, in_dim, out_dim]\n",
    "\n",
    "# 这里构造一个要与 nabla_imgs 相乘的向量\n",
    "# 你使用的是 net output: mlp(imgs, ts).unsqueeze(1) => shape [B,1,D']\n",
    "out_torch = mlp(imgs, ts)  # => (B,16)\n",
    "print(\"\\nJVP vector shape: \", out_torch.shape)\n",
    "\n",
    "# 类似做法: (B,1,D') x (B,D',D) -> (B,D)\n",
    "# einsum: 'bij, bjk -> bik'\n",
    "imgs_jvp = torch.einsum('bij,bjk->bik', out_torch.unsqueeze(1), nabla_imgs).squeeze(1)\n",
    "print(\"PyTorch final JVP shape: \", imgs_jvp.shape)  # => [B,D]\n",
    "\n",
    "#######################################################\n",
    "#                  2) Taichi 部分\n",
    "#######################################################\n",
    "import taichi as ti\n",
    "\n",
    "use_gpu = False  # 可以改成 True 在支持的环境下使用 GPU\n",
    "if use_gpu:\n",
    "    ti.init(arch=ti.gpu)\n",
    "else:\n",
    "    ti.init(arch=ti.cpu)\n",
    "\n",
    "B = batch_size\n",
    "dim_x = 8   # imgs 维度\n",
    "dim_t = 1    # ts 维度\n",
    "dim_in = dim_x + dim_t  # 17\n",
    "dim_h1 = 4\n",
    "dim_h2 = 4\n",
    "dim_out = 8\n",
    "\n",
    "# ------------------ Taichi 字段: MLP 参数 + 输入输出 ------------------\n",
    "W1 = ti.Matrix.field(dim_h1, dim_in, dtype=ti.f32, shape=())\n",
    "b1 = ti.Vector.field(dim_h1, dtype=ti.f32, shape=())\n",
    "\n",
    "W2 = ti.Matrix.field(dim_h2, dim_h1, dtype=ti.f32, shape=())\n",
    "b2 = ti.Vector.field(dim_h2, dtype=ti.f32, shape=())\n",
    "\n",
    "W3 = ti.Matrix.field(dim_out, dim_h2, dtype=ti.f32, shape=())\n",
    "b3 = ti.Vector.field(dim_out, dtype=ti.f32, shape=())\n",
    "\n",
    "# 输入: imgs + ts 合并成 (B,17)\n",
    "x_in = ti.Vector.field(dim_in, dtype=ti.f32, shape=(B,), needs_grad=True)\n",
    "y_out = ti.Vector.field(dim_out, dtype=ti.f32, shape=(B,), needs_grad=True)\n",
    "\n",
    "# 用于 JVP 的向量\n",
    "v = ti.Vector.field(dim_out, dtype=ti.f32, shape=(B,))\n",
    "# 用于存放 x_in.grad 的结果\n",
    "JVP_result = ti.Vector.field(dim_in, dtype=ti.f32, shape=(B,))\n",
    "\n",
    "# ------------------ Taichi Forward Kernel (与 ToyMLP 相同结构) ------------------\n",
    "@ti.kernel\n",
    "def forward_mlp():\n",
    "    for b in range(B):\n",
    "        # 读入 x_in[b], shape=17\n",
    "        # layer1: 17->8\n",
    "        z1 = W1[None] @ x_in[b] + b1[None]\n",
    "        for i in range(dim_h1):\n",
    "            z1[i] = ti.tanh(z1[i])\n",
    "        # layer2: 8->8\n",
    "        z2 = W2[None] @ z1 + b2[None]\n",
    "        for i in range(dim_h2):\n",
    "            z2[i] = ti.tanh(z2[i])\n",
    "        # layer3: 8->16\n",
    "        z3 = W3[None] @ z2 + b3[None]\n",
    "        y_out[b] = z3\n",
    "\n",
    "# ------------------ 辅助 Kernel ------------------\n",
    "@ti.kernel\n",
    "def clear_gradients():\n",
    "    for b in range(B):\n",
    "        x_in.grad[b].fill(0.0)\n",
    "        y_out.grad[b].fill(0.0)\n",
    "\n",
    "@ti.kernel\n",
    "def set_v_grad():\n",
    "    for b in range(B):\n",
    "        y_out.grad[b] = v[b]\n",
    "\n",
    "@ti.kernel\n",
    "def copy_grad_to_result():\n",
    "    for b in range(B):\n",
    "        JVP_result[b] = x_in.grad[b]\n",
    "\n",
    "# ------------------ 最终 JVP 计算 ------------------\n",
    "def taichi_compute_jvp():\n",
    "    clear_gradients()\n",
    "    set_v_grad()   # 将 y_out 的梯度设为 v\n",
    "    forward_mlp()  # 前向\n",
    "    forward_mlp.grad()  # 反向\n",
    "    copy_grad_to_result()\n",
    "    return JVP_result.to_numpy()\n",
    "\n",
    "#######################################################\n",
    "#       3) 参数对齐 + 结果对比\n",
    "#######################################################\n",
    "\n",
    "# (1) 将 PyTorch 中的参数拷贝到 Taichi (保证同样的 weight/bias)\n",
    "with torch.no_grad():\n",
    "    # layer0\n",
    "    W1_np = mlp.net[0].weight.detach().cpu().numpy()  # shape=(8,17)\n",
    "    b1_np = mlp.net[0].bias.detach().cpu().numpy()    # shape=(8,)\n",
    "    # layer1\n",
    "    W2_np = mlp.net[2].weight.detach().cpu().numpy()  # shape=(8,8)\n",
    "    b2_np = mlp.net[2].bias.detach().cpu().numpy()    # shape=(8,)\n",
    "    # layer2\n",
    "    W3_np = mlp.net[4].weight.detach().cpu().numpy()  # shape=(16,8)\n",
    "    b3_np = mlp.net[4].bias.detach().cpu().numpy()    # shape=(16,)\n",
    "\n",
    "# 赋值到 Taichi\n",
    "W1[None] = W1_np\n",
    "b1[None] = b1_np\n",
    "W2[None] = W2_np\n",
    "b2[None] = b2_np\n",
    "W3[None] = W3_np\n",
    "b3[None] = b3_np\n",
    "\n",
    "# (2) 将 PyTorch imgs + ts 合并到 Taichi x_in\n",
    "# imgs.shape=[B,16], ts.shape=[B]\n",
    "imgs_np = imgs.detach().cpu().numpy()\n",
    "ts_np   = ts.detach().cpu().numpy().reshape(-1, 1)  # shape=(B,1)\n",
    "x_in_np = np.concatenate([imgs_np, ts_np], axis=1)  # => shape [B,17]\n",
    "for i in range(B):\n",
    "    x_in[i] = x_in_np[i]\n",
    "\n",
    "# (3) 构造 v: analog of PyTorch => out_torch: (B,16)\n",
    "out_np = out_torch.detach().cpu().numpy()\n",
    "for i in range(B):\n",
    "    v[i] = out_np[i]\n",
    "\n",
    "# (4) Taichi 前向 + JVP\n",
    "forward_mlp()  # 预热\n",
    "taichi_jvp = taichi_compute_jvp()  # => shape [B,17]\n",
    "\n",
    "# (5) 对比与 PyTorch 计算的 imgs_jvp\n",
    "# PyTorch里 imgs_jvp.shape=[B,16]，而 Taichi 这里是 [B,17] (包含了对 ts 的梯度)\n",
    "# 如果只关心对 imgs 的梯度, 取 taichi_jvp[:, :16]\n",
    "taichi_jvp_imgs = taichi_jvp[:, :16]\n",
    "\n",
    "print(\"\\nTaichi's JVP w.r.t. x_in (imgs + ts) has shape:\", taichi_jvp.shape)\n",
    "print(\"  => w.r.t. imgs shape is\", taichi_jvp_imgs.shape)\n",
    "\n",
    "# 我们只对比 w.r.t. imgs 的 16 维\n",
    "taichi_vs_pyt = taichi_jvp_imgs - imgs_jvp.detach().cpu().numpy()\n",
    "\n",
    "max_diff = np.max(np.abs(taichi_vs_pyt))\n",
    "print(f\"Compare partial gradient w.r.t. 'imgs' => max abs diff: {max_diff:.3e}\")\n",
    "print(\"Taichi JVP sample0[:5]:\", taichi_jvp_imgs[0,:5])\n",
    "print(\"PyTorch JVP sample0[:5]:\", imgs_jvp.detach().cpu().numpy()[0,:5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
