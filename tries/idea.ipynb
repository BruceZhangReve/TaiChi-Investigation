{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n",
      "CPU Time: 5.5037 seconds\n",
      "MPS Time: 0.7264 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "torch.backends.mps.is_available()\n",
    "\n",
    "import torch\n",
    "import time\n",
    "\n",
    "device_cpu = torch.device(\"cpu\")\n",
    "device_mps = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "model_cpu = torch.nn.Linear(1000, 1000).to(device_cpu)\n",
    "model_mps = torch.nn.Linear(1000, 1000).to(device_mps)\n",
    "\n",
    "inputs_cpu = torch.randn(1000, 1000).to(device_cpu)\n",
    "inputs_mps = torch.randn(1000, 1000).to(device_mps)\n",
    "\n",
    "# Test CPU Time\n",
    "start_time = time.time()\n",
    "for _ in range(500):\n",
    "    outputs_cpu = model_cpu(inputs_cpu)\n",
    "cpu_time = time.time() - start_time\n",
    "print(f\"CPU Time: {cpu_time:.4f} seconds\")\n",
    "\n",
    "# Test MPS Time\n",
    "start_time = time.time()\n",
    "for _ in range(500):\n",
    "    outputs_mps = model_mps(inputs_mps)\n",
    "torch.mps.synchronize()  # Make sure MPS compeletes the computation\n",
    "mps_time = time.time() - start_time\n",
    "print(f\"MPS Time: {mps_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.autograd.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes in a tensor $\\mathbf{y} \\in \\mathbb{R}^{B \\times D'}$, where $B$ is the batch size and $D'$ is the output dimension, and an input tensor $\\mathbf{x} \\in \\mathbb{R}^{B \\times D}$, where $D$ is the input dimension. By default, it also takes a gradient output tensor $\\mathbf{v} \\in \\mathbb{R}^{B \\times D'}$. \n",
    "\n",
    "This function computes the **Jacobian-Vector Product (JVP)**, **not** the full Jacobian matrix $J \\in \\mathbb{R}^{B \\times D' \\times D}$. The resulting product $J^T \\mathbf{v}$ has the shape $\\mathbb{R}^{B \\times D}$. Here, $J^T$ refers to swapping the second and third dimensions of the Jacobian, i.e., $J^T \\in \\mathbb{R}^{B \\times D \\times D'}$.\n",
    "\n",
    "From the **Einstein summation** perspective, this operation can be thought of as:\n",
    "\n",
    "$$\n",
    "\\left[J^T \\mathbf{v}\\right]_{b, d} = \\sum_{d'=1}^{D'} \\frac{\\partial y_b^{d'}}{\\partial x_b^d} \\cdot v_b^{d'}\n",
    "$$\n",
    "\n",
    "Or, in PyTorch's **`einsum`** notation:\n",
    "\n",
    "$$\n",
    "\\texttt{torch.einsum(b d d', b d' -> b d, J, v)}\n",
    "$$\n",
    "\n",
    "Example Scenario:\n",
    "\n",
    "Now, suppose we have a function $f: \\mathbb{R}^2 \\rightarrow \\mathbb{R}^3$, with a batch size $B=2$. If you want to compute $\\frac{\\partial y_2}{\\partial x_2}$ for **batch 1**, you can set:\n",
    "\n",
    "$$\n",
    "\\mathbf{v} = \\begin{bmatrix} 0 & 1 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This setting ensures that only the second output dimension of the first batch contributes to the gradient computation. The result of `torch.autograd.grad` will then give you:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y_2^{(1)}}{\\partial \\mathbf{x}^{(1)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(4.), tensor(27.))\n",
      "(tensor([[4.],\n",
      "        [0.]]),)\n",
      "x = \n",
      " tensor([[2., 3.],\n",
      "        [3., 4.]], requires_grad=True)\n",
      "w = \n",
      " tensor([[0.5000, 0.5000],\n",
      "        [0.2500, 0.2500],\n",
      "        [0.5000, 0.5000]])\n",
      "y = x w^T\n",
      " tensor([[2.5000, 1.2500, 2.5000],\n",
      "        [3.5000, 1.7500, 3.5000]], grad_fn=<MmBackward0>)\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# A simple illustration for torch.autograd\n",
    "\n",
    "##########\n",
    "#Look at this to see what torhc.grad.autograd returns\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "z = torch.tensor(3.0, requires_grad=True)\n",
    "# compute dy/dx and dy/dz\n",
    "y = x ** 2 + z ** 3\n",
    "print(torch.autograd.grad(y, [x, z])) #It returns a tuple\n",
    "\n",
    "##########\n",
    "# Now let's take batch into consideration\n",
    "x = torch.tensor([[2.0],[3.0]], requires_grad=True) #[B,D]\n",
    "# compute dy/dx and dy/dz\n",
    "y = x ** 2 #[B,D']\n",
    "print(torch.autograd.grad(y, x, grad_outputs=torch.tensor([[1],[0]]))) #It returns a tuple\n",
    "#Setting gradeints this way we enable only focusing on gradient we care about (no cross batches)\n",
    "\n",
    "##########\n",
    "# What if x is a vector?\n",
    "x = torch.tensor([[2.0, 3.0],[3.0, 4.0]], requires_grad=True) #[B,D]\n",
    "w = torch.tensor([[.5, .5],[.25, .25],[.5, .5]]) #[3,2]\n",
    "# compute dy/dx and dy/dz\n",
    "y = torch.matmul(x, w.T) #[B,D'] [2,3] in this case, then J^T would be [B,D,D'] = [2,2,3]\n",
    "grad_outputs = torch.tensor([[1, 0, 0], [0, 0, 0]])  # is the vector we mentioned above [B,D'] = [2,3]\n",
    "#Only calculate gradient for sample 1 and y1, and this is \n",
    "# [[1*dy1/dx1 + 0*dy2/dx1 + 0*dy3/dx1], \n",
    "#  [0*dy1/dx2 + 0*dy2/dx2 + 0*dy3/dx2]]  #WRONG UNDERSTANDING?\n",
    "print(\"x = \\n\",x)\n",
    "print(\"w = \\n\",w)\n",
    "print(\"y = x w^T\\n\",y)\n",
    "\n",
    "print(torch.autograd.grad(y, x, grad_outputs=grad_outputs)[0]) #[B,D]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "Jacobian Size [B,D',D]: torch.Size([3, 784, 784])\n",
      "JVP Result [B,D]: torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import torch\n",
    "\n",
    "sys.path.append('/Users/zhanglige/Desktop/JP-Lab/Code/Velocity_Flow_Matching/')\n",
    "import dnnlib\n",
    "from training.networks import ToyMLP\n",
    "\n",
    "#set up device first\n",
    "device_name = 'mps' #can swap this to cuda:0, etc pending on resources\n",
    "device = torch.device(device_name)\n",
    "print(device)\n",
    "\n",
    "#create ToyMLP instance, \n",
    "#adjust it to train mode, tracking grads and pass it to device\n",
    "mlp = ToyMLP(dim=784, time_varying=True, n_hidden=3, w=64)\n",
    "mlp.train().to(device)\n",
    "\n",
    "#first, set up inputs for net \n",
    "#am choosing small batch size to make computation faster \n",
    "batch_size = 3\n",
    "flat_data_dim = 784 \n",
    "imgs = torch.randn(batch_size, flat_data_dim).type(torch.float32).to(device)\n",
    "ts = torch.rand(batch_size, device=device) \n",
    "\n",
    "#ok now calc Jacobian of net_out w.r.t imgs input \n",
    "#set requires_grad to True for net inputs... \n",
    "ts.requires_grad=True\n",
    "imgs.requires_grad=True\n",
    "\n",
    "\n",
    "#small method to compute desired Jacobian, for a batch \n",
    "def batch_jacobian(model, imgs, ts):\n",
    "    \"\"\"Computes the Jacobian of a batch of outputs w.r.t a batch of inputs.\"\"\"\n",
    "\n",
    "    batch_size, input_size = imgs.shape #[B,D]\n",
    "    output_size = model(imgs, ts).shape[1] #[D']\n",
    "\n",
    "    jacobian = torch.zeros(batch_size, output_size, input_size) #[B,D',D]\n",
    "\n",
    "    #note that we loop over batch AND dimensions here! \n",
    "    for i in range(batch_size): #for b \\in [b_1,...,b_B]\n",
    "        for j in range(output_size): #For y \\in (y_1,y_2,...,y_{D'})\n",
    "            grad_outputs = torch.zeros_like(model(imgs, ts)) #[B,D']\n",
    "            grad_outputs[i, j] = 1.0 #Weight for gradient, but you may consider as a filter\n",
    "            jacobian[i, j] = torch.autograd.grad(\n",
    "                model(imgs, ts), imgs, grad_outputs=grad_outputs, retain_graph=True\n",
    "            )[0][i]\n",
    "        #in one loop, you fill dy_j/dx_1,dy_j/dx_2,...,dy_j/dx_D\n",
    "    #in one loop, you fill a jacobian matrix for one batch\n",
    "\n",
    "    return jacobian\n",
    "\n",
    "ag_jac = batch_jacobian(mlp, imgs, ts)\n",
    "#check that shape matches - this should already be collapsed across extra batch dim\n",
    "print(\"Jacobian Size [B,D',D]:\",ag_jac.shape) #[B,D',D] #This is the Jacobian (which we fill one row at a time through batches)\n",
    "\n",
    "#ok, now compute jvp (product the output vector)\n",
    "nabla_imgs_ag = ag_jac.transpose(2,1) #transpose to get grad  #[B,D,D']\n",
    "imgs_jvp_ag = torch.einsum('bij, bjk -> bik', mlp(imgs, ts).unsqueeze(1), nabla_imgs_ag.to(device)).squeeze(1) #bs, dim \n",
    "#[B,1,D'] [B,D',D] -> [B,1,D], after squeeze it would be [B,D]\n",
    "print(\"JVP Result [B,D]:\",imgs_jvp_ag.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.functional.jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JVP Result: torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import torch\n",
    "\n",
    "sys.path.append('/Users/zhanglige/Desktop/JP-Lab/Code/Velocity_Flow_Matching/')\n",
    "import dnnlib\n",
    "from training.networks import ToyMLP\n",
    "\n",
    "device = torch.device('mps') \n",
    "\n",
    "mlp = ToyMLP(dim=784, time_varying=True, n_hidden=3, w=64).train().to(device)\n",
    "\n",
    "batch_size = 3\n",
    "imgs = torch.randn(batch_size, 784, device=device, requires_grad=True)\n",
    "ts = torch.rand(batch_size, device=device, requires_grad=True)\n",
    "\n",
    "y = mlp(imgs, ts)\n",
    "\n",
    "# Direct calculation of JVP\n",
    "v = y.clone().detach()  #Check below\n",
    "imgs_jvp = torch.autograd.grad(\n",
    "    outputs=y,\n",
    "    inputs=imgs,\n",
    "    grad_outputs=v, # Directly use the model output as weight here\n",
    "    retain_graph=True\n",
    ")[0]\n",
    "\n",
    "print(\"JVP Result:\", imgs_jvp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.allclose(imgs_jvp.detach().cpu().numpy(), imgs_jvp_ag.detach().cpu().numpy())\n",
    "np.allclose(imgs_jvp.detach().cpu().numpy(), imgs_jvp_ag.detach().cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
