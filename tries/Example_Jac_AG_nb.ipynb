{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d56b935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n",
      "CPU Time: 6.1144 seconds\n",
      "MPS Time: 0.6143 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "torch.backends.mps.is_available()\n",
    "\n",
    "import torch\n",
    "import time\n",
    "\n",
    "device_cpu = torch.device(\"cpu\")\n",
    "device_mps = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "model_cpu = torch.nn.Linear(1000, 1000).to(device_cpu)\n",
    "model_mps = torch.nn.Linear(1000, 1000).to(device_mps)\n",
    "\n",
    "inputs_cpu = torch.randn(1000, 1000).to(device_cpu)\n",
    "inputs_mps = torch.randn(1000, 1000).to(device_mps)\n",
    "\n",
    "# Test CPU Time\n",
    "start_time = time.time()\n",
    "for _ in range(500):\n",
    "    outputs_cpu = model_cpu(inputs_cpu)\n",
    "cpu_time = time.time() - start_time\n",
    "print(f\"CPU Time: {cpu_time:.4f} seconds\")\n",
    "\n",
    "# Test MPS Time\n",
    "start_time = time.time()\n",
    "for _ in range(500):\n",
    "    outputs_mps = model_mps(inputs_mps)\n",
    "torch.mps.synchronize()  # Make sure MPS compeletes the computation\n",
    "mps_time = time.time() - start_time\n",
    "print(f\"MPS Time: {mps_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403a3bcf-5478-49b3-ba72-3f560d9d8b18",
   "metadata": {},
   "source": [
    "### Goals: \n",
    "* Showcase computation of our desired jacobian-vector product (JVP) for a small toy network case using either:\n",
    "* 1) torch.autograd.functional.jacobian (which has $\\mathcal{O}(d^2)$ complexity),\n",
    "  2) torch.autograd.grad (which has $\\mathcal{O}(d)$ complexity using for loops,\n",
    "  3) using torch.autograd.grad + torch.vmap to avoid loop over batch dimension.\n",
    "* This is meant as a simple/early example for Bruce to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f95dcd29-ffd5-4e2a-84f5-38663457d730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#general \n",
    "import numpy as np\n",
    "import os, sys\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40ffa4c6-ad0b-4ab3-b2ea-2c03611d7e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specific to vfm repo\n",
    "#this is mostly so you have a net to work with ... \n",
    "#sys.path.append('/home/dfd4/vfm_D_min_clipping/') #swap this for path to VFM repo in your local machine \n",
    "sys.path.append('/Users/zhanglige/Desktop/JP-Lab/Code/Velocity_Flow_Matching/')\n",
    "import dnnlib\n",
    "from training.networks import ToyMLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7690db58-19f0-4fa5-9418-f555c021dee7",
   "metadata": {},
   "source": [
    "### Construct a network to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4412ab0d-7fd0-465a-94ca-0496df867ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#set up device first\n",
    "device_name = 'cpu' #can swap this to cuda:0, etc pending on resources\n",
    "device = torch.device(device_name)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77b7e241-d170-469a-86ff-b04058f483b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToyMLP(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=785, out_features=64, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (7): Tanh()\n",
       "    (8): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (9): Tanh()\n",
       "    (10): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (11): Tanh()\n",
       "    (12): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (13): Tanh()\n",
       "    (14): Linear(in_features=64, out_features=784, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create ToyMLP instance, \n",
    "#adjust it to train mode, tracking grads and pass it to device\n",
    "mlp = ToyMLP(dim=784, time_varying=True, n_hidden=6, w=64)\n",
    "mlp.train().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171cb6b8-fad8-4af3-b56d-d22731df296a",
   "metadata": {},
   "source": [
    "#### Above yields a simple mlp with $n$ number of hidden layers, each with width $w$.  \n",
    "#### Note that input feature size is data_dim + 1. This is by design, as this net takes also a time input which is concatenated to flattened image input.\n",
    "### Let's compute one desired jvp using torch.autograd.functional.jacobian ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e38af1af-f1d7-4002-b2f4-f38ad26ece9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, set up inputs for net \n",
    "#am choosing small batch size to make computation faster \n",
    "batch_size = 3\n",
    "flat_data_dim = 784 \n",
    "imgs = torch.randn(batch_size, flat_data_dim).type(torch.float32).to(device)\n",
    "ts = torch.rand(batch_size, device=device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "915d3554-8f52-452f-8a2c-ef0f0c6e6aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok now calc Jacobian of net_out w.r.t imgs input \n",
    "#set requires_grad to True for net inputs... \n",
    "ts.requires_grad=True\n",
    "imgs.requires_grad=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66acc1b1",
   "metadata": {},
   "source": [
    "We can think img as $x \\in \\mathbb{R}^{B \\times D}$, where $B$ is the batch size and $D$ is the input dimension. Also ts as $t \\in \\mathbb{R}^{B}$. The mlp we denote as y, thus the overall function can be written as $y=f(x,t) \\in \\mathbb{R}^{B \\times D'}$, where $D'$ is the output dimension.\n",
    "\n",
    "Now if we don't consider batch, y,x are vectors, the Jacobian will be an intuitive matrix. But if we consider batches, it's a bit complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "817b78af-273a-4dbd-9799-c5402794a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_jac = torch.autograd.functional.jacobian(mlp, (imgs, ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36c4f0ad-90d2-42d3-a22a-780986b2e738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([3, 784, 3, 784])\n",
      "torch.Size([3, 784, 3])\n"
     ]
    }
   ],
   "source": [
    "print(len(mlp_jac))\n",
    "print(mlp_jac[0].shape) #[B,D',B,D]\n",
    "print(mlp_jac[1].shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa84b8c6-d1a4-4349-8c8c-1c68a18d2521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-1.1842e-05,  1.5036e-04,  3.9824e-04,  ...,  2.2364e-04,\n",
      "          3.0547e-04,  2.9108e-04]])\n"
     ]
    }
   ],
   "source": [
    "Jacobian_4_img = mlp_jac[0]\n",
    "print(Jacobian_4_img[2][1])\n",
    "\n",
    "#This is the y_1 in batch 2, it should only be the output of x_i from batch 2, so we see the first two rows \n",
    "#should be "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5737c9e3-b6b6-4316-8c17-e0b8184082fd",
   "metadata": {},
   "source": [
    "#### Note that torch's Jac method will produce one Jacobian output per each input of the function call. So, in this case, first item in list is Jacobian of net output w.r.t. first (i.e., imgs) input and second item is Jacobian of output w.r.t second input (ts).\n",
    "#### Note also that Jac ouputs have several FULL ZERO rows... This is because batch items are independent of each other - that is, we can collapse across batch dim in dim==2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e0ea92-bf74-4533-bc9b-3f16f99e55cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784, 3, 784])\n",
      "torch.Size([3, 784, 784])\n",
      "torch.Size([3, 784, 784])\n",
      "tensor([[ 0.0030, -0.0006,  0.0008,  ...,  0.0011,  0.0006,  0.0009],\n",
      "        [ 0.0027, -0.0002,  0.0014,  ...,  0.0011,  0.0006,  0.0014],\n",
      "        [ 0.0023, -0.0009,  0.0006,  ...,  0.0009,  0.0003,  0.0004]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "#imgs jvp\n",
    "print(mlp_jac[0].shape)\n",
    "torch_jac = torch.sum(mlp_jac[0], dim=2) #collapse over extra batch dim, see comment above # then it would be img:(B,D',D)\n",
    "print(torch_jac.shape) #[B,D',D]\n",
    "nabla_imgs = torch_jac.transpose(2,1) #transpose, to get gradient (SHOULDN\"T BE?? I THINK)\n",
    "print(nabla_imgs.shape) #[B,D,D']\n",
    "#compute actual u \\cdot nabla product. \n",
    "#note that this is between above nabla_imgs and corresponding network output tensor u \n",
    "imgs_jvp = torch.einsum('bij, bjk -> bik', mlp(imgs, ts).unsqueeze(1), nabla_imgs).squeeze(1) #bs, dim \n",
    "#mlp(imgs, ts).unsqueeze(1):=[B,1,D']    bjk:=[B,D',D] -> [B,1,D], after squeeze it would be [B,D]\n",
    "#if you think about it [D',D] is the correct shape of a Jacobian\n",
    "print(imgs_jvp)\n",
    "print(imgs_jvp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eb0e9a",
   "metadata": {},
   "source": [
    "For each batch sample \\( i \\), you are computing the following:\n",
    "\n",
    "$$\n",
    "\\text{imgs\\_jvp}^{(i)} = \\mathbf{y}^{(i)} \\cdot \\left( \\frac{\\partial \\mathbf{y}^{(i)}}{\\partial \\mathbf{x}^{(i)}} \\right)^\\top\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $ \\mathbf{y}^{(i)} \\in \\mathbb{R}^{D'} $: The model output for the \\( i \\)-th sample.\n",
    "- $ \\frac{\\partial \\mathbf{y}^{(i)}}{\\partial \\mathbf{x}^{(i)}} \\in \\mathbb{R}^{D' \\times D} $: The Jacobian matrix for the \\( i \\)-th sample, representing the partial derivatives of the output with respect to the input.\n",
    "- $ \\text{imgs\\_jvp}^{(i)} \\in \\mathbb{R}^{D} $: The result of the Jacobian-Vector Product, which is a vector of the same dimension as the input features.\n",
    "\n",
    "This operation represents how the model output, when treated as a vector, interacts with the gradient (Jacobian) of the model with respect to the input, effectively measuring how changes in the input affect the output in the direction of the output itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfa7105-1149-45a3-9371-e213b53a0f56",
   "metadata": {},
   "source": [
    "#### Let's de-compress the above a bit. First, we take Jacobian of net output w.r.t to its first input (imgs) and sum/collapse it over dimension 2, since each output is only dependent on its corresponding batch input. \n",
    "#### Then, we take transpose w.r.t to 2 last dimensions - this is d/t relationship between Jacobian and gradients... Typically, for scalar functions, gradients are column vectors (i.e., rows of Jac transposed)\n",
    "#### Will triple check with John that this is needed here... \n",
    "\n",
    "#### Finally, we use an Einstein summation to compute the desired product over the batch -- this yields the $u \\cdot \\nabla $ product we want for the Lie derivative calculation.\n",
    "\n",
    "#### Couple of points here: \n",
    "* 1) In actual code, this will take LONGER to run, because in there imgs are not just simple inputs, but instead interpolations between original data and outputs of another, separate encoder network.\n",
    "  2) Additionally, we compute two such JVPs (one for flow net, another for dynamics net) and compute partial derivative w.r.t. to time argument (ts) as well.\n",
    "  3) All of these then go into computing out Lie derivative loss: $\\mathcal{L}_{Lie} = \\partial_{\\tau} \\mathbf{v} + \\mathbf{u} \\cdot \\nabla_{\\mathbf{v}} - \\mathbf{v} \\cdot \\nabla_{\\mathbf{u}}$\n",
    "\n",
    "### Ok, let's compute same jvp now with torch.grad.autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55182468-36ff-4448-babe-eac56c0cc0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784, 784])\n"
     ]
    }
   ],
   "source": [
    "#small method to compute desired Jacobian, for a batch \n",
    "def batch_jacobian(model, imgs, ts):\n",
    "    \"\"\"Computes the Jacobian of a batch of outputs w.r.t a batch of inputs.\"\"\"\n",
    "\n",
    "    batch_size, input_size = imgs.shape #[B,D]\n",
    "    output_size = model(imgs, ts).shape[1] #[D']\n",
    "\n",
    "    jacobian = torch.zeros(batch_size, output_size, input_size) #[B,D',D]\n",
    "\n",
    "    #note that we loop over batch AND dimensions here! \n",
    "    for i in range(batch_size): #for b \\in [b_1,...,b_B]\n",
    "        for j in range(output_size): #For y \\in (y_1,y_2,...,y_{D'})\n",
    "            grad_outputs = torch.zeros_like(model(imgs, ts)) #[B,D']\n",
    "            grad_outputs[i, j] = 1.0 #Weight for gradient, but you may consider as a filter\n",
    "            jacobian[i, j] = torch.autograd.grad(\n",
    "                model(imgs, ts), imgs, grad_outputs=grad_outputs, retain_graph=True\n",
    "            )[0][i]\n",
    "\n",
    "    return jacobian\n",
    "\n",
    "ag_jac = batch_jacobian(mlp, imgs, ts)\n",
    "#check that shape matches - this should already be collapsed across extra batch dim\n",
    "print(ag_jac.shape) #[B,D',D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b41400-f673-4815-9da4-cdce540abb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that this produces correct/desired Jac \n",
    "np.allclose(ag_jac.detach().cpu().numpy(), torch_jac.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460dace5-2258-44b8-ba58-ec88bfd85563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok, now compute jvp \n",
    "nabla_imgs_ag = ag_jac.transpose(2,1) #transpose to get grad \n",
    "imgs_jvp_ag = torch.einsum('bij, bjk -> bik', mlp(imgs, ts).unsqueeze(1), nabla_imgs_ag.to(device)).squeeze(1) #bs, dim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1eb1b6b4-7b88-4451-a73c-28cb103bd7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that these results are indeed the same... \n",
    "np.allclose(imgs_jvp.detach().cpu().numpy(), imgs_jvp_ag.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27510a65-5253-4209-8da4-ff5c3f364d03",
   "metadata": {},
   "source": [
    "### Ok, now let's use torch vmap and torch.autograd.grad to run the above \n",
    "#### This avoids loop over batch items but comes at cost of larger VRAM requirements..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b86df40b-8267-46ba-ba35-97235cb72bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_jvp = lambda v: torch.autograd.grad(mlp(imgs, ts), imgs, v, retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1d740d0-b2de-4196-8f95-397ae1d38576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to create v vector we will need to vmap over batch elements \n",
    "def build_IN_vmap(shape):\n",
    "    \"\"\"\n",
    "    Computes IN we will use for vmapping \n",
    "    over torch.autograd.grad call \n",
    "    \"\"\"\n",
    "    I_N = []\n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            curr_IN = torch.zeros(shape)\n",
    "            curr_IN[i, j]=1\n",
    "            I_N.append(curr_IN)\n",
    "    I_N = torch.cat(I_N, dim=0)\n",
    "    return I_N.reshape((-1, shape[0], shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4738e32-085b-46fa-9923-915cb18148b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmap_v = build_IN_vmap((6, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d299a364-4607-4897-8d1a-65e80cb2aa62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4704, 6, 784])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that shape matches - should be [bs*dim, bs, dim]\n",
    "vmap_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f87ae15-ccae-470b-b8f3-a5d4cc27a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmap_ag_jac = torch.vmap(get_jvp)(vmap_v.type(torch.float32).to(device))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e36b197a-112b-4554-8086-7a9dc4dbc1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4704, 6, 784])\n",
      "torch.Size([6, 784, 784])\n"
     ]
    }
   ],
   "source": [
    "#check that shape is correct - should be [bs*dim, bs, dim]\n",
    "print(vmap_ag_jac.shape)\n",
    "#reshape this output to [bs, dim, bs, dim]\n",
    "#collapse over dim==2 as before \n",
    "vmap_ag_jac = vmap_ag_jac.reshape(batch_size, imgs.shape[1], batch_size, imgs.shape[1])\n",
    "vmap_ag_jac = vmap_ag_jac.sum(2)\n",
    "print(vmap_ag_jac.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f80ec3b4-f227-4b9d-9e9a-5c5a17b876c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:1')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ok now check that this is indeed identical to previous results obtained with loop + AG and Jac \n",
    "vmap_ag_jac.all() == ag_jac.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "30991ecc-d493-4307-ad9e-be1667ca934d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:1')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vmap_ag_jac.all() == torch_jac.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7f97fd-dc51-4e0e-b523-2b554cddea5e",
   "metadata": {},
   "source": [
    "### General Comments: \n",
    "1) I need to check with John if indeed I need to transpose Jac here? This is how I implemented things originally and this matches results computed by hand.\n",
    "2) All cases above still end up computing a Jacobian different ways and then doing the Jacobian vector product... This is in part due to difficulty of finding a proper vector $v$ that would correctly select ONLY desired row of Jac and ALSO multiply it by our corresponding output vector.\n",
    "3) I don't think this is possible really? But discuss it with John and then update Bruce "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25985fbf-9109-4e18-a3f8-88bba2a05be5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
